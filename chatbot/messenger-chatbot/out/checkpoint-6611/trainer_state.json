{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 100,
  "global_step": 6611,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.003025260928755105,
      "grad_norm": 2.7358992099761963,
      "learning_rate": 0.00019942520042353653,
      "loss": 1.7192,
      "step": 20
    },
    {
      "epoch": 0.00605052185751021,
      "grad_norm": 2.1517529487609863,
      "learning_rate": 0.00019882014823778551,
      "loss": 1.0018,
      "step": 40
    },
    {
      "epoch": 0.009075782786265316,
      "grad_norm": 3.3457658290863037,
      "learning_rate": 0.0001982150960520345,
      "loss": 1.0597,
      "step": 60
    },
    {
      "epoch": 0.01210104371502042,
      "grad_norm": 1.6105998754501343,
      "learning_rate": 0.0001976100438662835,
      "loss": 0.8939,
      "step": 80
    },
    {
      "epoch": 0.015126304643775526,
      "grad_norm": 2.057692766189575,
      "learning_rate": 0.00019700499168053245,
      "loss": 0.9166,
      "step": 100
    },
    {
      "epoch": 0.015126304643775526,
      "eval_loss": 0.9579565525054932,
      "eval_runtime": 19.7294,
      "eval_samples_per_second": 21.491,
      "eval_steps_per_second": 21.491,
      "step": 100
    },
    {
      "epoch": 0.018151565572530632,
      "grad_norm": 2.08015513420105,
      "learning_rate": 0.00019639993949478144,
      "loss": 0.8146,
      "step": 120
    },
    {
      "epoch": 0.021176826501285734,
      "grad_norm": 1.641641616821289,
      "learning_rate": 0.00019579488730903043,
      "loss": 0.9411,
      "step": 140
    },
    {
      "epoch": 0.02420208743004084,
      "grad_norm": 2.610161066055298,
      "learning_rate": 0.00019518983512327939,
      "loss": 0.8736,
      "step": 160
    },
    {
      "epoch": 0.027227348358795946,
      "grad_norm": 1.7825337648391724,
      "learning_rate": 0.00019458478293752837,
      "loss": 0.8609,
      "step": 180
    },
    {
      "epoch": 0.030252609287551052,
      "grad_norm": 1.9225019216537476,
      "learning_rate": 0.00019397973075177736,
      "loss": 0.9171,
      "step": 200
    },
    {
      "epoch": 0.030252609287551052,
      "eval_loss": 0.9068834781646729,
      "eval_runtime": 19.7138,
      "eval_samples_per_second": 21.508,
      "eval_steps_per_second": 21.508,
      "step": 200
    },
    {
      "epoch": 0.033277870216306155,
      "grad_norm": 1.6987513303756714,
      "learning_rate": 0.00019337467856602632,
      "loss": 0.8251,
      "step": 220
    },
    {
      "epoch": 0.036303131145061264,
      "grad_norm": 1.884016752243042,
      "learning_rate": 0.0001927696263802753,
      "loss": 0.9399,
      "step": 240
    },
    {
      "epoch": 0.039328392073816366,
      "grad_norm": 2.2156999111175537,
      "learning_rate": 0.0001921645741945243,
      "loss": 0.7905,
      "step": 260
    },
    {
      "epoch": 0.04235365300257147,
      "grad_norm": 1.4303187131881714,
      "learning_rate": 0.00019155952200877328,
      "loss": 0.8589,
      "step": 280
    },
    {
      "epoch": 0.04537891393132658,
      "grad_norm": 1.9779813289642334,
      "learning_rate": 0.00019095446982302224,
      "loss": 0.7862,
      "step": 300
    },
    {
      "epoch": 0.04537891393132658,
      "eval_loss": 0.883784830570221,
      "eval_runtime": 19.7488,
      "eval_samples_per_second": 21.47,
      "eval_steps_per_second": 21.47,
      "step": 300
    },
    {
      "epoch": 0.04840417486008168,
      "grad_norm": 1.2624390125274658,
      "learning_rate": 0.00019034941763727123,
      "loss": 0.7179,
      "step": 320
    },
    {
      "epoch": 0.05142943578883679,
      "grad_norm": 1.779275894165039,
      "learning_rate": 0.00018974436545152022,
      "loss": 0.7956,
      "step": 340
    },
    {
      "epoch": 0.05445469671759189,
      "grad_norm": 2.030967950820923,
      "learning_rate": 0.00018913931326576918,
      "loss": 0.8135,
      "step": 360
    },
    {
      "epoch": 0.057479957646346995,
      "grad_norm": 1.791231632232666,
      "learning_rate": 0.00018853426108001817,
      "loss": 0.8112,
      "step": 380
    },
    {
      "epoch": 0.060505218575102104,
      "grad_norm": 2.0068130493164062,
      "learning_rate": 0.00018792920889426716,
      "loss": 0.7818,
      "step": 400
    },
    {
      "epoch": 0.060505218575102104,
      "eval_loss": 0.8605982661247253,
      "eval_runtime": 19.7112,
      "eval_samples_per_second": 21.511,
      "eval_steps_per_second": 21.511,
      "step": 400
    },
    {
      "epoch": 0.0635304795038572,
      "grad_norm": 1.7953499555587769,
      "learning_rate": 0.00018732415670851612,
      "loss": 0.7605,
      "step": 420
    },
    {
      "epoch": 0.06655574043261231,
      "grad_norm": 1.8131242990493774,
      "learning_rate": 0.00018671910452276508,
      "loss": 0.7677,
      "step": 440
    },
    {
      "epoch": 0.06958100136136741,
      "grad_norm": 1.9230575561523438,
      "learning_rate": 0.00018611405233701406,
      "loss": 0.8159,
      "step": 460
    },
    {
      "epoch": 0.07260626229012253,
      "grad_norm": 1.7812618017196655,
      "learning_rate": 0.00018550900015126305,
      "loss": 0.7572,
      "step": 480
    },
    {
      "epoch": 0.07563152321887763,
      "grad_norm": 2.057173013687134,
      "learning_rate": 0.00018490394796551204,
      "loss": 0.7776,
      "step": 500
    },
    {
      "epoch": 0.07563152321887763,
      "eval_loss": 0.8267760276794434,
      "eval_runtime": 19.7495,
      "eval_samples_per_second": 21.469,
      "eval_steps_per_second": 21.469,
      "step": 500
    },
    {
      "epoch": 0.07865678414763273,
      "grad_norm": 1.4671710729599,
      "learning_rate": 0.000184298895779761,
      "loss": 0.7067,
      "step": 520
    },
    {
      "epoch": 0.08168204507638784,
      "grad_norm": 1.5956073999404907,
      "learning_rate": 0.00018369384359401,
      "loss": 0.7836,
      "step": 540
    },
    {
      "epoch": 0.08470730600514294,
      "grad_norm": 1.4484962224960327,
      "learning_rate": 0.00018308879140825897,
      "loss": 0.7439,
      "step": 560
    },
    {
      "epoch": 0.08773256693389805,
      "grad_norm": 1.23758065700531,
      "learning_rate": 0.00018248373922250793,
      "loss": 0.7189,
      "step": 580
    },
    {
      "epoch": 0.09075782786265316,
      "grad_norm": 1.8471429347991943,
      "learning_rate": 0.00018187868703675692,
      "loss": 0.8658,
      "step": 600
    },
    {
      "epoch": 0.09075782786265316,
      "eval_loss": 0.815207839012146,
      "eval_runtime": 19.765,
      "eval_samples_per_second": 21.452,
      "eval_steps_per_second": 21.452,
      "step": 600
    },
    {
      "epoch": 0.09378308879140826,
      "grad_norm": 2.068779230117798,
      "learning_rate": 0.0001812736348510059,
      "loss": 0.8345,
      "step": 620
    },
    {
      "epoch": 0.09680834972016336,
      "grad_norm": 1.4106450080871582,
      "learning_rate": 0.00018066858266525487,
      "loss": 0.7473,
      "step": 640
    },
    {
      "epoch": 0.09983361064891846,
      "grad_norm": 1.6807520389556885,
      "learning_rate": 0.00018006353047950386,
      "loss": 0.7678,
      "step": 660
    },
    {
      "epoch": 0.10285887157767358,
      "grad_norm": 1.8839104175567627,
      "learning_rate": 0.00017945847829375285,
      "loss": 0.7185,
      "step": 680
    },
    {
      "epoch": 0.10588413250642868,
      "grad_norm": 2.2183778285980225,
      "learning_rate": 0.00017885342610800183,
      "loss": 0.7531,
      "step": 700
    },
    {
      "epoch": 0.10588413250642868,
      "eval_loss": 0.7851540446281433,
      "eval_runtime": 19.7273,
      "eval_samples_per_second": 21.493,
      "eval_steps_per_second": 21.493,
      "step": 700
    },
    {
      "epoch": 0.10890939343518379,
      "grad_norm": 1.4555901288986206,
      "learning_rate": 0.0001782483739222508,
      "loss": 0.6782,
      "step": 720
    },
    {
      "epoch": 0.11193465436393889,
      "grad_norm": 0.9321559071540833,
      "learning_rate": 0.00017764332173649978,
      "loss": 0.7321,
      "step": 740
    },
    {
      "epoch": 0.11495991529269399,
      "grad_norm": 1.5714967250823975,
      "learning_rate": 0.00017703826955074877,
      "loss": 0.8113,
      "step": 760
    },
    {
      "epoch": 0.1179851762214491,
      "grad_norm": 1.6952208280563354,
      "learning_rate": 0.00017643321736499773,
      "loss": 0.7457,
      "step": 780
    },
    {
      "epoch": 0.12101043715020421,
      "grad_norm": 1.7294319868087769,
      "learning_rate": 0.00017582816517924672,
      "loss": 0.6733,
      "step": 800
    },
    {
      "epoch": 0.12101043715020421,
      "eval_loss": 0.7790629267692566,
      "eval_runtime": 19.7264,
      "eval_samples_per_second": 21.494,
      "eval_steps_per_second": 21.494,
      "step": 800
    },
    {
      "epoch": 0.12403569807895931,
      "grad_norm": 2.172360420227051,
      "learning_rate": 0.0001752231129934957,
      "loss": 0.7631,
      "step": 820
    },
    {
      "epoch": 0.1270609590077144,
      "grad_norm": 2.8398561477661133,
      "learning_rate": 0.00017461806080774466,
      "loss": 0.7515,
      "step": 840
    },
    {
      "epoch": 0.13008621993646952,
      "grad_norm": 1.9286377429962158,
      "learning_rate": 0.00017401300862199365,
      "loss": 0.7325,
      "step": 860
    },
    {
      "epoch": 0.13311148086522462,
      "grad_norm": 1.5455955266952515,
      "learning_rate": 0.00017340795643624264,
      "loss": 0.7393,
      "step": 880
    },
    {
      "epoch": 0.13613674179397972,
      "grad_norm": 2.284513235092163,
      "learning_rate": 0.00017280290425049163,
      "loss": 0.736,
      "step": 900
    },
    {
      "epoch": 0.13613674179397972,
      "eval_loss": 0.7762773633003235,
      "eval_runtime": 19.7209,
      "eval_samples_per_second": 21.5,
      "eval_steps_per_second": 21.5,
      "step": 900
    },
    {
      "epoch": 0.13916200272273482,
      "grad_norm": 1.5892245769500732,
      "learning_rate": 0.0001721978520647406,
      "loss": 0.7062,
      "step": 920
    },
    {
      "epoch": 0.14218726365148995,
      "grad_norm": 2.0134530067443848,
      "learning_rate": 0.00017159279987898957,
      "loss": 0.7306,
      "step": 940
    },
    {
      "epoch": 0.14521252458024506,
      "grad_norm": 1.5649652481079102,
      "learning_rate": 0.00017098774769323856,
      "loss": 0.7855,
      "step": 960
    },
    {
      "epoch": 0.14823778550900016,
      "grad_norm": 1.5226439237594604,
      "learning_rate": 0.00017038269550748752,
      "loss": 0.6516,
      "step": 980
    },
    {
      "epoch": 0.15126304643775526,
      "grad_norm": 2.4127275943756104,
      "learning_rate": 0.0001697776433217365,
      "loss": 0.6974,
      "step": 1000
    },
    {
      "epoch": 0.15126304643775526,
      "eval_loss": 0.7767017483711243,
      "eval_runtime": 19.7237,
      "eval_samples_per_second": 21.497,
      "eval_steps_per_second": 21.497,
      "step": 1000
    },
    {
      "epoch": 0.15428830736651036,
      "grad_norm": 3.0903537273406982,
      "learning_rate": 0.0001691725911359855,
      "loss": 0.6694,
      "step": 1020
    },
    {
      "epoch": 0.15731356829526547,
      "grad_norm": 1.6948184967041016,
      "learning_rate": 0.00016856753895023446,
      "loss": 0.7115,
      "step": 1040
    },
    {
      "epoch": 0.16033882922402057,
      "grad_norm": 1.811510682106018,
      "learning_rate": 0.00016796248676448345,
      "loss": 0.7139,
      "step": 1060
    },
    {
      "epoch": 0.16336409015277567,
      "grad_norm": 2.838146924972534,
      "learning_rate": 0.00016735743457873243,
      "loss": 0.7469,
      "step": 1080
    },
    {
      "epoch": 0.16638935108153077,
      "grad_norm": 2.0043609142303467,
      "learning_rate": 0.00016675238239298142,
      "loss": 0.729,
      "step": 1100
    },
    {
      "epoch": 0.16638935108153077,
      "eval_loss": 0.7550007104873657,
      "eval_runtime": 19.6929,
      "eval_samples_per_second": 21.531,
      "eval_steps_per_second": 21.531,
      "step": 1100
    },
    {
      "epoch": 0.16941461201028588,
      "grad_norm": 2.225311279296875,
      "learning_rate": 0.00016614733020723038,
      "loss": 0.7012,
      "step": 1120
    },
    {
      "epoch": 0.172439872939041,
      "grad_norm": 1.9645134210586548,
      "learning_rate": 0.00016554227802147937,
      "loss": 0.6325,
      "step": 1140
    },
    {
      "epoch": 0.1754651338677961,
      "grad_norm": 1.9986798763275146,
      "learning_rate": 0.00016493722583572836,
      "loss": 0.7151,
      "step": 1160
    },
    {
      "epoch": 0.1784903947965512,
      "grad_norm": 1.4217013120651245,
      "learning_rate": 0.00016433217364997732,
      "loss": 0.6729,
      "step": 1180
    },
    {
      "epoch": 0.1815156557253063,
      "grad_norm": 1.8604066371917725,
      "learning_rate": 0.0001637271214642263,
      "loss": 0.6352,
      "step": 1200
    },
    {
      "epoch": 0.1815156557253063,
      "eval_loss": 0.7404077053070068,
      "eval_runtime": 19.6998,
      "eval_samples_per_second": 21.523,
      "eval_steps_per_second": 21.523,
      "step": 1200
    },
    {
      "epoch": 0.18454091665406142,
      "grad_norm": 1.2625097036361694,
      "learning_rate": 0.0001631220692784753,
      "loss": 0.5552,
      "step": 1220
    },
    {
      "epoch": 0.18756617758281652,
      "grad_norm": 2.2763640880584717,
      "learning_rate": 0.00016251701709272428,
      "loss": 0.7465,
      "step": 1240
    },
    {
      "epoch": 0.19059143851157162,
      "grad_norm": 3.0701487064361572,
      "learning_rate": 0.0001619119649069732,
      "loss": 0.6952,
      "step": 1260
    },
    {
      "epoch": 0.19361669944032672,
      "grad_norm": 1.8225717544555664,
      "learning_rate": 0.0001613069127212222,
      "loss": 0.7212,
      "step": 1280
    },
    {
      "epoch": 0.19664196036908183,
      "grad_norm": 1.6951347589492798,
      "learning_rate": 0.0001607018605354712,
      "loss": 0.708,
      "step": 1300
    },
    {
      "epoch": 0.19664196036908183,
      "eval_loss": 0.7347073554992676,
      "eval_runtime": 19.695,
      "eval_samples_per_second": 21.528,
      "eval_steps_per_second": 21.528,
      "step": 1300
    },
    {
      "epoch": 0.19966722129783693,
      "grad_norm": 2.0624449253082275,
      "learning_rate": 0.00016009680834972018,
      "loss": 0.62,
      "step": 1320
    },
    {
      "epoch": 0.20269248222659203,
      "grad_norm": 2.216402530670166,
      "learning_rate": 0.00015949175616396914,
      "loss": 0.7314,
      "step": 1340
    },
    {
      "epoch": 0.20571774315534716,
      "grad_norm": 1.3566447496414185,
      "learning_rate": 0.00015888670397821812,
      "loss": 0.6348,
      "step": 1360
    },
    {
      "epoch": 0.20874300408410226,
      "grad_norm": 1.5367330312728882,
      "learning_rate": 0.0001582816517924671,
      "loss": 0.6477,
      "step": 1380
    },
    {
      "epoch": 0.21176826501285737,
      "grad_norm": 1.656816840171814,
      "learning_rate": 0.00015767659960671607,
      "loss": 0.6714,
      "step": 1400
    },
    {
      "epoch": 0.21176826501285737,
      "eval_loss": 0.7354539632797241,
      "eval_runtime": 19.7316,
      "eval_samples_per_second": 21.488,
      "eval_steps_per_second": 21.488,
      "step": 1400
    },
    {
      "epoch": 0.21479352594161247,
      "grad_norm": 1.762200951576233,
      "learning_rate": 0.00015707154742096506,
      "loss": 0.6782,
      "step": 1420
    },
    {
      "epoch": 0.21781878687036757,
      "grad_norm": 1.651383638381958,
      "learning_rate": 0.00015646649523521405,
      "loss": 0.6396,
      "step": 1440
    },
    {
      "epoch": 0.22084404779912267,
      "grad_norm": 2.477858543395996,
      "learning_rate": 0.000155861443049463,
      "loss": 0.751,
      "step": 1460
    },
    {
      "epoch": 0.22386930872787777,
      "grad_norm": 1.3612083196640015,
      "learning_rate": 0.000155256390863712,
      "loss": 0.7072,
      "step": 1480
    },
    {
      "epoch": 0.22689456965663288,
      "grad_norm": 2.251497507095337,
      "learning_rate": 0.00015465133867796098,
      "loss": 0.67,
      "step": 1500
    },
    {
      "epoch": 0.22689456965663288,
      "eval_loss": 0.7334622144699097,
      "eval_runtime": 19.8116,
      "eval_samples_per_second": 21.402,
      "eval_steps_per_second": 21.402,
      "step": 1500
    },
    {
      "epoch": 0.22991983058538798,
      "grad_norm": 2.191267728805542,
      "learning_rate": 0.00015404628649220997,
      "loss": 0.6573,
      "step": 1520
    },
    {
      "epoch": 0.23294509151414308,
      "grad_norm": 1.6655114889144897,
      "learning_rate": 0.00015344123430645893,
      "loss": 0.7506,
      "step": 1540
    },
    {
      "epoch": 0.2359703524428982,
      "grad_norm": 1.6735138893127441,
      "learning_rate": 0.00015283618212070792,
      "loss": 0.6051,
      "step": 1560
    },
    {
      "epoch": 0.23899561337165331,
      "grad_norm": 2.2092647552490234,
      "learning_rate": 0.0001522311299349569,
      "loss": 0.7227,
      "step": 1580
    },
    {
      "epoch": 0.24202087430040842,
      "grad_norm": 1.843448281288147,
      "learning_rate": 0.00015162607774920587,
      "loss": 0.6115,
      "step": 1600
    },
    {
      "epoch": 0.24202087430040842,
      "eval_loss": 0.7235091328620911,
      "eval_runtime": 19.7826,
      "eval_samples_per_second": 21.433,
      "eval_steps_per_second": 21.433,
      "step": 1600
    },
    {
      "epoch": 0.24504613522916352,
      "grad_norm": 1.9450386762619019,
      "learning_rate": 0.00015102102556345485,
      "loss": 0.7424,
      "step": 1620
    },
    {
      "epoch": 0.24807139615791862,
      "grad_norm": 2.1460094451904297,
      "learning_rate": 0.00015041597337770384,
      "loss": 0.7384,
      "step": 1640
    },
    {
      "epoch": 0.2510966570866737,
      "grad_norm": 2.3600192070007324,
      "learning_rate": 0.0001498109211919528,
      "loss": 0.6244,
      "step": 1660
    },
    {
      "epoch": 0.2541219180154288,
      "grad_norm": 1.4930094480514526,
      "learning_rate": 0.0001492058690062018,
      "loss": 0.6177,
      "step": 1680
    },
    {
      "epoch": 0.25714717894418393,
      "grad_norm": 2.4958226680755615,
      "learning_rate": 0.00014860081682045078,
      "loss": 0.7031,
      "step": 1700
    },
    {
      "epoch": 0.25714717894418393,
      "eval_loss": 0.7298868894577026,
      "eval_runtime": 19.7492,
      "eval_samples_per_second": 21.469,
      "eval_steps_per_second": 21.469,
      "step": 1700
    },
    {
      "epoch": 0.26017243987293903,
      "grad_norm": 1.678222894668579,
      "learning_rate": 0.00014799576463469976,
      "loss": 0.7157,
      "step": 1720
    },
    {
      "epoch": 0.26319770080169413,
      "grad_norm": 2.0956454277038574,
      "learning_rate": 0.00014739071244894872,
      "loss": 0.783,
      "step": 1740
    },
    {
      "epoch": 0.26622296173044924,
      "grad_norm": 1.4228489398956299,
      "learning_rate": 0.0001467856602631977,
      "loss": 0.6372,
      "step": 1760
    },
    {
      "epoch": 0.26924822265920434,
      "grad_norm": 1.4692546129226685,
      "learning_rate": 0.0001461806080774467,
      "loss": 0.6521,
      "step": 1780
    },
    {
      "epoch": 0.27227348358795944,
      "grad_norm": 1.965698003768921,
      "learning_rate": 0.00014557555589169566,
      "loss": 0.6327,
      "step": 1800
    },
    {
      "epoch": 0.27227348358795944,
      "eval_loss": 0.724902331829071,
      "eval_runtime": 19.7401,
      "eval_samples_per_second": 21.479,
      "eval_steps_per_second": 21.479,
      "step": 1800
    },
    {
      "epoch": 0.27529874451671454,
      "grad_norm": 1.2612144947052002,
      "learning_rate": 0.00014497050370594465,
      "loss": 0.6255,
      "step": 1820
    },
    {
      "epoch": 0.27832400544546965,
      "grad_norm": 0.983456015586853,
      "learning_rate": 0.00014436545152019363,
      "loss": 0.5872,
      "step": 1840
    },
    {
      "epoch": 0.2813492663742248,
      "grad_norm": 1.7331284284591675,
      "learning_rate": 0.0001437603993344426,
      "loss": 0.5676,
      "step": 1860
    },
    {
      "epoch": 0.2843745273029799,
      "grad_norm": 1.8044198751449585,
      "learning_rate": 0.00014315534714869158,
      "loss": 0.7157,
      "step": 1880
    },
    {
      "epoch": 0.287399788231735,
      "grad_norm": 1.73271906375885,
      "learning_rate": 0.00014255029496294057,
      "loss": 0.7455,
      "step": 1900
    },
    {
      "epoch": 0.287399788231735,
      "eval_loss": 0.7155874967575073,
      "eval_runtime": 19.7105,
      "eval_samples_per_second": 21.511,
      "eval_steps_per_second": 21.511,
      "step": 1900
    },
    {
      "epoch": 0.2904250491604901,
      "grad_norm": 1.5224603414535522,
      "learning_rate": 0.00014194524277718956,
      "loss": 0.6519,
      "step": 1920
    },
    {
      "epoch": 0.2934503100892452,
      "grad_norm": 1.7360714673995972,
      "learning_rate": 0.00014134019059143852,
      "loss": 0.6773,
      "step": 1940
    },
    {
      "epoch": 0.2964755710180003,
      "grad_norm": 1.655665397644043,
      "learning_rate": 0.0001407351384056875,
      "loss": 0.6097,
      "step": 1960
    },
    {
      "epoch": 0.2995008319467554,
      "grad_norm": 1.8416719436645508,
      "learning_rate": 0.0001401300862199365,
      "loss": 0.6213,
      "step": 1980
    },
    {
      "epoch": 0.3025260928755105,
      "grad_norm": 2.8540170192718506,
      "learning_rate": 0.00013952503403418545,
      "loss": 0.6331,
      "step": 2000
    },
    {
      "epoch": 0.3025260928755105,
      "eval_loss": 0.7155461311340332,
      "eval_runtime": 19.6991,
      "eval_samples_per_second": 21.524,
      "eval_steps_per_second": 21.524,
      "step": 2000
    },
    {
      "epoch": 0.3055513538042656,
      "grad_norm": 2.005613088607788,
      "learning_rate": 0.00013891998184843444,
      "loss": 0.6887,
      "step": 2020
    },
    {
      "epoch": 0.3085766147330207,
      "grad_norm": 1.3984211683273315,
      "learning_rate": 0.00013831492966268343,
      "loss": 0.7319,
      "step": 2040
    },
    {
      "epoch": 0.31160187566177583,
      "grad_norm": 1.9746860265731812,
      "learning_rate": 0.00013770987747693242,
      "loss": 0.7099,
      "step": 2060
    },
    {
      "epoch": 0.31462713659053093,
      "grad_norm": 1.95365309715271,
      "learning_rate": 0.00013710482529118135,
      "loss": 0.6219,
      "step": 2080
    },
    {
      "epoch": 0.31765239751928603,
      "grad_norm": 0.8318776488304138,
      "learning_rate": 0.00013649977310543034,
      "loss": 0.5908,
      "step": 2100
    },
    {
      "epoch": 0.31765239751928603,
      "eval_loss": 0.7152171730995178,
      "eval_runtime": 19.6851,
      "eval_samples_per_second": 21.539,
      "eval_steps_per_second": 21.539,
      "step": 2100
    },
    {
      "epoch": 0.32067765844804114,
      "grad_norm": 2.4798288345336914,
      "learning_rate": 0.00013589472091967932,
      "loss": 0.6827,
      "step": 2120
    },
    {
      "epoch": 0.32370291937679624,
      "grad_norm": 1.8636990785598755,
      "learning_rate": 0.0001352896687339283,
      "loss": 0.6935,
      "step": 2140
    },
    {
      "epoch": 0.32672818030555134,
      "grad_norm": 1.2762795686721802,
      "learning_rate": 0.00013468461654817727,
      "loss": 0.6291,
      "step": 2160
    },
    {
      "epoch": 0.32975344123430644,
      "grad_norm": 1.580161213874817,
      "learning_rate": 0.00013407956436242626,
      "loss": 0.6229,
      "step": 2180
    },
    {
      "epoch": 0.33277870216306155,
      "grad_norm": 2.2084262371063232,
      "learning_rate": 0.00013347451217667525,
      "loss": 0.6482,
      "step": 2200
    },
    {
      "epoch": 0.33277870216306155,
      "eval_loss": 0.702829897403717,
      "eval_runtime": 19.6744,
      "eval_samples_per_second": 21.551,
      "eval_steps_per_second": 21.551,
      "step": 2200
    },
    {
      "epoch": 0.33580396309181665,
      "grad_norm": 1.2687268257141113,
      "learning_rate": 0.0001328694599909242,
      "loss": 0.6211,
      "step": 2220
    },
    {
      "epoch": 0.33882922402057175,
      "grad_norm": 0.6823651790618896,
      "learning_rate": 0.0001322644078051732,
      "loss": 0.6473,
      "step": 2240
    },
    {
      "epoch": 0.34185448494932685,
      "grad_norm": 1.698464274406433,
      "learning_rate": 0.00013165935561942218,
      "loss": 0.6468,
      "step": 2260
    },
    {
      "epoch": 0.344879745878082,
      "grad_norm": 1.4071323871612549,
      "learning_rate": 0.00013105430343367114,
      "loss": 0.6195,
      "step": 2280
    },
    {
      "epoch": 0.3479050068068371,
      "grad_norm": 2.103036880493164,
      "learning_rate": 0.00013044925124792013,
      "loss": 0.6218,
      "step": 2300
    },
    {
      "epoch": 0.3479050068068371,
      "eval_loss": 0.6919780373573303,
      "eval_runtime": 19.7955,
      "eval_samples_per_second": 21.419,
      "eval_steps_per_second": 21.419,
      "step": 2300
    },
    {
      "epoch": 0.3509302677355922,
      "grad_norm": 2.7448103427886963,
      "learning_rate": 0.00012984419906216912,
      "loss": 0.6196,
      "step": 2320
    },
    {
      "epoch": 0.3539555286643473,
      "grad_norm": 1.1181952953338623,
      "learning_rate": 0.0001292391468764181,
      "loss": 0.6322,
      "step": 2340
    },
    {
      "epoch": 0.3569807895931024,
      "grad_norm": 3.9307050704956055,
      "learning_rate": 0.00012863409469066707,
      "loss": 0.5783,
      "step": 2360
    },
    {
      "epoch": 0.3600060505218575,
      "grad_norm": 1.1288424730300903,
      "learning_rate": 0.00012802904250491605,
      "loss": 0.6085,
      "step": 2380
    },
    {
      "epoch": 0.3630313114506126,
      "grad_norm": 2.3647220134735107,
      "learning_rate": 0.00012742399031916504,
      "loss": 0.7123,
      "step": 2400
    },
    {
      "epoch": 0.3630313114506126,
      "eval_loss": 0.6942049860954285,
      "eval_runtime": 19.7616,
      "eval_samples_per_second": 21.456,
      "eval_steps_per_second": 21.456,
      "step": 2400
    },
    {
      "epoch": 0.36605657237936773,
      "grad_norm": 2.044384717941284,
      "learning_rate": 0.000126818938133414,
      "loss": 0.5854,
      "step": 2420
    },
    {
      "epoch": 0.36908183330812283,
      "grad_norm": 1.9962341785430908,
      "learning_rate": 0.000126213885947663,
      "loss": 0.6149,
      "step": 2440
    },
    {
      "epoch": 0.37210709423687793,
      "grad_norm": 1.8780779838562012,
      "learning_rate": 0.00012560883376191198,
      "loss": 0.5977,
      "step": 2460
    },
    {
      "epoch": 0.37513235516563304,
      "grad_norm": 2.505727767944336,
      "learning_rate": 0.00012500378157616094,
      "loss": 0.6773,
      "step": 2480
    },
    {
      "epoch": 0.37815761609438814,
      "grad_norm": 1.7645210027694702,
      "learning_rate": 0.00012439872939040992,
      "loss": 0.5685,
      "step": 2500
    },
    {
      "epoch": 0.37815761609438814,
      "eval_loss": 0.6814694404602051,
      "eval_runtime": 19.6812,
      "eval_samples_per_second": 21.543,
      "eval_steps_per_second": 21.543,
      "step": 2500
    },
    {
      "epoch": 0.38118287702314324,
      "grad_norm": 2.4783401489257812,
      "learning_rate": 0.0001237936772046589,
      "loss": 0.6021,
      "step": 2520
    },
    {
      "epoch": 0.38420813795189834,
      "grad_norm": 1.6005011796951294,
      "learning_rate": 0.0001231886250189079,
      "loss": 0.665,
      "step": 2540
    },
    {
      "epoch": 0.38723339888065345,
      "grad_norm": 4.751867294311523,
      "learning_rate": 0.00012258357283315686,
      "loss": 0.6531,
      "step": 2560
    },
    {
      "epoch": 0.39025865980940855,
      "grad_norm": 1.2179111242294312,
      "learning_rate": 0.00012197852064740585,
      "loss": 0.616,
      "step": 2580
    },
    {
      "epoch": 0.39328392073816365,
      "grad_norm": 2.624879837036133,
      "learning_rate": 0.00012137346846165482,
      "loss": 0.6611,
      "step": 2600
    },
    {
      "epoch": 0.39328392073816365,
      "eval_loss": 0.6804173588752747,
      "eval_runtime": 19.6808,
      "eval_samples_per_second": 21.544,
      "eval_steps_per_second": 21.544,
      "step": 2600
    },
    {
      "epoch": 0.39630918166691875,
      "grad_norm": 1.483232021331787,
      "learning_rate": 0.00012076841627590381,
      "loss": 0.5932,
      "step": 2620
    },
    {
      "epoch": 0.39933444259567386,
      "grad_norm": 2.4103269577026367,
      "learning_rate": 0.00012016336409015278,
      "loss": 0.6532,
      "step": 2640
    },
    {
      "epoch": 0.40235970352442896,
      "grad_norm": 2.071833610534668,
      "learning_rate": 0.00011955831190440177,
      "loss": 0.6642,
      "step": 2660
    },
    {
      "epoch": 0.40538496445318406,
      "grad_norm": 2.8337249755859375,
      "learning_rate": 0.00011895325971865074,
      "loss": 0.6051,
      "step": 2680
    },
    {
      "epoch": 0.4084102253819392,
      "grad_norm": 1.8115959167480469,
      "learning_rate": 0.00011834820753289972,
      "loss": 0.5921,
      "step": 2700
    },
    {
      "epoch": 0.4084102253819392,
      "eval_loss": 0.6697669625282288,
      "eval_runtime": 19.6796,
      "eval_samples_per_second": 21.545,
      "eval_steps_per_second": 21.545,
      "step": 2700
    },
    {
      "epoch": 0.4114354863106943,
      "grad_norm": 1.877428650856018,
      "learning_rate": 0.0001177431553471487,
      "loss": 0.5432,
      "step": 2720
    },
    {
      "epoch": 0.4144607472394494,
      "grad_norm": 1.2978976964950562,
      "learning_rate": 0.00011713810316139768,
      "loss": 0.6115,
      "step": 2740
    },
    {
      "epoch": 0.4174860081682045,
      "grad_norm": 2.2210235595703125,
      "learning_rate": 0.00011653305097564667,
      "loss": 0.5683,
      "step": 2760
    },
    {
      "epoch": 0.42051126909695963,
      "grad_norm": 1.646323323249817,
      "learning_rate": 0.00011592799878989564,
      "loss": 0.583,
      "step": 2780
    },
    {
      "epoch": 0.42353653002571473,
      "grad_norm": 1.583387851715088,
      "learning_rate": 0.00011532294660414462,
      "loss": 0.5666,
      "step": 2800
    },
    {
      "epoch": 0.42353653002571473,
      "eval_loss": 0.6727234721183777,
      "eval_runtime": 19.6685,
      "eval_samples_per_second": 21.557,
      "eval_steps_per_second": 21.557,
      "step": 2800
    },
    {
      "epoch": 0.42656179095446983,
      "grad_norm": 2.6072256565093994,
      "learning_rate": 0.0001147178944183936,
      "loss": 0.579,
      "step": 2820
    },
    {
      "epoch": 0.42958705188322494,
      "grad_norm": 2.2013442516326904,
      "learning_rate": 0.00011411284223264258,
      "loss": 0.638,
      "step": 2840
    },
    {
      "epoch": 0.43261231281198004,
      "grad_norm": 1.4409432411193848,
      "learning_rate": 0.00011350779004689156,
      "loss": 0.5642,
      "step": 2860
    },
    {
      "epoch": 0.43563757374073514,
      "grad_norm": 1.82463800907135,
      "learning_rate": 0.00011290273786114054,
      "loss": 0.6836,
      "step": 2880
    },
    {
      "epoch": 0.43866283466949024,
      "grad_norm": 1.2041770219802856,
      "learning_rate": 0.0001122976856753895,
      "loss": 0.5515,
      "step": 2900
    },
    {
      "epoch": 0.43866283466949024,
      "eval_loss": 0.6672995090484619,
      "eval_runtime": 19.6724,
      "eval_samples_per_second": 21.553,
      "eval_steps_per_second": 21.553,
      "step": 2900
    },
    {
      "epoch": 0.44168809559824534,
      "grad_norm": 1.124572515487671,
      "learning_rate": 0.00011169263348963847,
      "loss": 0.564,
      "step": 2920
    },
    {
      "epoch": 0.44471335652700045,
      "grad_norm": 1.3275026082992554,
      "learning_rate": 0.00011108758130388746,
      "loss": 0.5685,
      "step": 2940
    },
    {
      "epoch": 0.44773861745575555,
      "grad_norm": 1.702936053276062,
      "learning_rate": 0.00011048252911813643,
      "loss": 0.6198,
      "step": 2960
    },
    {
      "epoch": 0.45076387838451065,
      "grad_norm": 2.1784591674804688,
      "learning_rate": 0.00010987747693238541,
      "loss": 0.6246,
      "step": 2980
    },
    {
      "epoch": 0.45378913931326575,
      "grad_norm": 1.3942161798477173,
      "learning_rate": 0.0001092724247466344,
      "loss": 0.6465,
      "step": 3000
    },
    {
      "epoch": 0.45378913931326575,
      "eval_loss": 0.6603625416755676,
      "eval_runtime": 19.6629,
      "eval_samples_per_second": 21.563,
      "eval_steps_per_second": 21.563,
      "step": 3000
    },
    {
      "epoch": 0.45681440024202086,
      "grad_norm": 1.8972851037979126,
      "learning_rate": 0.00010866737256088337,
      "loss": 0.6555,
      "step": 3020
    },
    {
      "epoch": 0.45983966117077596,
      "grad_norm": 3.068100690841675,
      "learning_rate": 0.00010806232037513236,
      "loss": 0.6014,
      "step": 3040
    },
    {
      "epoch": 0.46286492209953106,
      "grad_norm": 2.087458848953247,
      "learning_rate": 0.00010745726818938133,
      "loss": 0.5906,
      "step": 3060
    },
    {
      "epoch": 0.46589018302828616,
      "grad_norm": 1.5986427068710327,
      "learning_rate": 0.0001068522160036303,
      "loss": 0.596,
      "step": 3080
    },
    {
      "epoch": 0.4689154439570413,
      "grad_norm": 1.8641270399093628,
      "learning_rate": 0.00010624716381787929,
      "loss": 0.5404,
      "step": 3100
    },
    {
      "epoch": 0.4689154439570413,
      "eval_loss": 0.656804084777832,
      "eval_runtime": 19.6971,
      "eval_samples_per_second": 21.526,
      "eval_steps_per_second": 21.526,
      "step": 3100
    },
    {
      "epoch": 0.4719407048857964,
      "grad_norm": 1.0596988201141357,
      "learning_rate": 0.00010564211163212827,
      "loss": 0.6418,
      "step": 3120
    },
    {
      "epoch": 0.4749659658145515,
      "grad_norm": 2.028691530227661,
      "learning_rate": 0.00010503705944637725,
      "loss": 0.6363,
      "step": 3140
    },
    {
      "epoch": 0.47799122674330663,
      "grad_norm": 1.1367343664169312,
      "learning_rate": 0.00010443200726062623,
      "loss": 0.5955,
      "step": 3160
    },
    {
      "epoch": 0.48101648767206173,
      "grad_norm": 1.6215983629226685,
      "learning_rate": 0.00010382695507487522,
      "loss": 0.6493,
      "step": 3180
    },
    {
      "epoch": 0.48404174860081683,
      "grad_norm": 1.7444379329681396,
      "learning_rate": 0.00010322190288912419,
      "loss": 0.5631,
      "step": 3200
    },
    {
      "epoch": 0.48404174860081683,
      "eval_loss": 0.654722273349762,
      "eval_runtime": 19.655,
      "eval_samples_per_second": 21.572,
      "eval_steps_per_second": 21.572,
      "step": 3200
    },
    {
      "epoch": 0.48706700952957194,
      "grad_norm": 2.885878801345825,
      "learning_rate": 0.00010261685070337316,
      "loss": 0.5724,
      "step": 3220
    },
    {
      "epoch": 0.49009227045832704,
      "grad_norm": 1.9484437704086304,
      "learning_rate": 0.00010201179851762215,
      "loss": 0.6066,
      "step": 3240
    },
    {
      "epoch": 0.49311753138708214,
      "grad_norm": 1.9819945096969604,
      "learning_rate": 0.00010140674633187113,
      "loss": 0.6455,
      "step": 3260
    },
    {
      "epoch": 0.49614279231583724,
      "grad_norm": 1.5649805068969727,
      "learning_rate": 0.00010080169414612011,
      "loss": 0.5885,
      "step": 3280
    },
    {
      "epoch": 0.49916805324459235,
      "grad_norm": 1.4681174755096436,
      "learning_rate": 0.00010019664196036909,
      "loss": 0.5812,
      "step": 3300
    },
    {
      "epoch": 0.49916805324459235,
      "eval_loss": 0.6477753520011902,
      "eval_runtime": 19.6533,
      "eval_samples_per_second": 21.574,
      "eval_steps_per_second": 21.574,
      "step": 3300
    },
    {
      "epoch": 0.5021933141733474,
      "grad_norm": 1.8477030992507935,
      "learning_rate": 9.959158977461806e-05,
      "loss": 0.5838,
      "step": 3320
    },
    {
      "epoch": 0.5052185751021026,
      "grad_norm": 1.4824883937835693,
      "learning_rate": 9.898653758886705e-05,
      "loss": 0.559,
      "step": 3340
    },
    {
      "epoch": 0.5082438360308577,
      "grad_norm": 1.0283931493759155,
      "learning_rate": 9.838148540311602e-05,
      "loss": 0.6345,
      "step": 3360
    },
    {
      "epoch": 0.5112690969596128,
      "grad_norm": 1.864168405532837,
      "learning_rate": 9.777643321736501e-05,
      "loss": 0.5871,
      "step": 3380
    },
    {
      "epoch": 0.5142943578883679,
      "grad_norm": 1.910379409790039,
      "learning_rate": 9.717138103161398e-05,
      "loss": 0.6283,
      "step": 3400
    },
    {
      "epoch": 0.5142943578883679,
      "eval_loss": 0.6454669833183289,
      "eval_runtime": 19.6624,
      "eval_samples_per_second": 21.564,
      "eval_steps_per_second": 21.564,
      "step": 3400
    },
    {
      "epoch": 0.517319618817123,
      "grad_norm": 1.8338972330093384,
      "learning_rate": 9.656632884586296e-05,
      "loss": 0.5542,
      "step": 3420
    },
    {
      "epoch": 0.5203448797458781,
      "grad_norm": 1.4298774003982544,
      "learning_rate": 9.596127666011195e-05,
      "loss": 0.6339,
      "step": 3440
    },
    {
      "epoch": 0.5233701406746332,
      "grad_norm": 2.0120065212249756,
      "learning_rate": 9.535622447436092e-05,
      "loss": 0.53,
      "step": 3460
    },
    {
      "epoch": 0.5263954016033883,
      "grad_norm": 2.128446578979492,
      "learning_rate": 9.475117228860991e-05,
      "loss": 0.5687,
      "step": 3480
    },
    {
      "epoch": 0.5294206625321434,
      "grad_norm": 1.830553412437439,
      "learning_rate": 9.414612010285888e-05,
      "loss": 0.5414,
      "step": 3500
    },
    {
      "epoch": 0.5294206625321434,
      "eval_loss": 0.6530642509460449,
      "eval_runtime": 19.6659,
      "eval_samples_per_second": 21.56,
      "eval_steps_per_second": 21.56,
      "step": 3500
    },
    {
      "epoch": 0.5324459234608985,
      "grad_norm": 2.5004682540893555,
      "learning_rate": 9.354106791710786e-05,
      "loss": 0.5847,
      "step": 3520
    },
    {
      "epoch": 0.5354711843896536,
      "grad_norm": 1.9289336204528809,
      "learning_rate": 9.293601573135683e-05,
      "loss": 0.6381,
      "step": 3540
    },
    {
      "epoch": 0.5384964453184087,
      "grad_norm": 2.1880338191986084,
      "learning_rate": 9.23309635456058e-05,
      "loss": 0.6462,
      "step": 3560
    },
    {
      "epoch": 0.5415217062471638,
      "grad_norm": 1.5626609325408936,
      "learning_rate": 9.172591135985479e-05,
      "loss": 0.5297,
      "step": 3580
    },
    {
      "epoch": 0.5445469671759189,
      "grad_norm": 0.7348108291625977,
      "learning_rate": 9.112085917410376e-05,
      "loss": 0.5773,
      "step": 3600
    },
    {
      "epoch": 0.5445469671759189,
      "eval_loss": 0.6458190083503723,
      "eval_runtime": 19.6727,
      "eval_samples_per_second": 21.553,
      "eval_steps_per_second": 21.553,
      "step": 3600
    },
    {
      "epoch": 0.547572228104674,
      "grad_norm": 1.4622255563735962,
      "learning_rate": 9.051580698835275e-05,
      "loss": 0.6504,
      "step": 3620
    },
    {
      "epoch": 0.5505974890334291,
      "grad_norm": 1.498327612876892,
      "learning_rate": 8.991075480260173e-05,
      "loss": 0.534,
      "step": 3640
    },
    {
      "epoch": 0.5536227499621842,
      "grad_norm": 1.2810710668563843,
      "learning_rate": 8.93057026168507e-05,
      "loss": 0.6603,
      "step": 3660
    },
    {
      "epoch": 0.5566480108909393,
      "grad_norm": 2.5481812953948975,
      "learning_rate": 8.870065043109969e-05,
      "loss": 0.6607,
      "step": 3680
    },
    {
      "epoch": 0.5596732718196944,
      "grad_norm": 1.7754642963409424,
      "learning_rate": 8.809559824534866e-05,
      "loss": 0.6107,
      "step": 3700
    },
    {
      "epoch": 0.5596732718196944,
      "eval_loss": 0.647462010383606,
      "eval_runtime": 19.6809,
      "eval_samples_per_second": 21.544,
      "eval_steps_per_second": 21.544,
      "step": 3700
    },
    {
      "epoch": 0.5626985327484496,
      "grad_norm": 1.9071663618087769,
      "learning_rate": 8.749054605959765e-05,
      "loss": 0.52,
      "step": 3720
    },
    {
      "epoch": 0.5657237936772047,
      "grad_norm": 2.192490339279175,
      "learning_rate": 8.688549387384662e-05,
      "loss": 0.6214,
      "step": 3740
    },
    {
      "epoch": 0.5687490546059598,
      "grad_norm": 1.9817088842391968,
      "learning_rate": 8.62804416880956e-05,
      "loss": 0.5002,
      "step": 3760
    },
    {
      "epoch": 0.5717743155347149,
      "grad_norm": 2.018735408782959,
      "learning_rate": 8.567538950234458e-05,
      "loss": 0.6747,
      "step": 3780
    },
    {
      "epoch": 0.57479957646347,
      "grad_norm": 1.4285352230072021,
      "learning_rate": 8.507033731659356e-05,
      "loss": 0.6421,
      "step": 3800
    },
    {
      "epoch": 0.57479957646347,
      "eval_loss": 0.648239016532898,
      "eval_runtime": 19.6944,
      "eval_samples_per_second": 21.529,
      "eval_steps_per_second": 21.529,
      "step": 3800
    },
    {
      "epoch": 0.5778248373922251,
      "grad_norm": 1.9766002893447876,
      "learning_rate": 8.446528513084255e-05,
      "loss": 0.6024,
      "step": 3820
    },
    {
      "epoch": 0.5808500983209802,
      "grad_norm": 1.936525821685791,
      "learning_rate": 8.386023294509152e-05,
      "loss": 0.5924,
      "step": 3840
    },
    {
      "epoch": 0.5838753592497353,
      "grad_norm": 1.3088010549545288,
      "learning_rate": 8.32551807593405e-05,
      "loss": 0.5193,
      "step": 3860
    },
    {
      "epoch": 0.5869006201784904,
      "grad_norm": 1.9052947759628296,
      "learning_rate": 8.265012857358948e-05,
      "loss": 0.6501,
      "step": 3880
    },
    {
      "epoch": 0.5899258811072455,
      "grad_norm": 1.8301355838775635,
      "learning_rate": 8.204507638783846e-05,
      "loss": 0.538,
      "step": 3900
    },
    {
      "epoch": 0.5899258811072455,
      "eval_loss": 0.6424649953842163,
      "eval_runtime": 19.6977,
      "eval_samples_per_second": 21.525,
      "eval_steps_per_second": 21.525,
      "step": 3900
    },
    {
      "epoch": 0.5929511420360006,
      "grad_norm": 1.8959929943084717,
      "learning_rate": 8.144002420208744e-05,
      "loss": 0.5726,
      "step": 3920
    },
    {
      "epoch": 0.5959764029647557,
      "grad_norm": 2.7010233402252197,
      "learning_rate": 8.08349720163364e-05,
      "loss": 0.6028,
      "step": 3940
    },
    {
      "epoch": 0.5990016638935108,
      "grad_norm": 1.73496413230896,
      "learning_rate": 8.022991983058539e-05,
      "loss": 0.5871,
      "step": 3960
    },
    {
      "epoch": 0.6020269248222659,
      "grad_norm": 1.4684946537017822,
      "learning_rate": 7.962486764483437e-05,
      "loss": 0.5829,
      "step": 3980
    },
    {
      "epoch": 0.605052185751021,
      "grad_norm": 2.1915130615234375,
      "learning_rate": 7.901981545908335e-05,
      "loss": 0.5544,
      "step": 4000
    },
    {
      "epoch": 0.605052185751021,
      "eval_loss": 0.6340681910514832,
      "eval_runtime": 19.7003,
      "eval_samples_per_second": 21.523,
      "eval_steps_per_second": 21.523,
      "step": 4000
    },
    {
      "epoch": 0.6080774466797761,
      "grad_norm": 1.4633347988128662,
      "learning_rate": 7.841476327333233e-05,
      "loss": 0.6361,
      "step": 4020
    },
    {
      "epoch": 0.6111027076085312,
      "grad_norm": 0.9995923042297363,
      "learning_rate": 7.78097110875813e-05,
      "loss": 0.5251,
      "step": 4040
    },
    {
      "epoch": 0.6141279685372864,
      "grad_norm": 1.7272061109542847,
      "learning_rate": 7.720465890183029e-05,
      "loss": 0.5545,
      "step": 4060
    },
    {
      "epoch": 0.6171532294660415,
      "grad_norm": 1.123948097229004,
      "learning_rate": 7.659960671607926e-05,
      "loss": 0.6248,
      "step": 4080
    },
    {
      "epoch": 0.6201784903947966,
      "grad_norm": 1.9833505153656006,
      "learning_rate": 7.599455453032825e-05,
      "loss": 0.6461,
      "step": 4100
    },
    {
      "epoch": 0.6201784903947966,
      "eval_loss": 0.6268190145492554,
      "eval_runtime": 19.6873,
      "eval_samples_per_second": 21.537,
      "eval_steps_per_second": 21.537,
      "step": 4100
    },
    {
      "epoch": 0.6232037513235517,
      "grad_norm": 2.4644391536712646,
      "learning_rate": 7.538950234457722e-05,
      "loss": 0.6447,
      "step": 4120
    },
    {
      "epoch": 0.6262290122523068,
      "grad_norm": 1.778547763824463,
      "learning_rate": 7.47844501588262e-05,
      "loss": 0.5813,
      "step": 4140
    },
    {
      "epoch": 0.6292542731810619,
      "grad_norm": 2.4987454414367676,
      "learning_rate": 7.417939797307519e-05,
      "loss": 0.6046,
      "step": 4160
    },
    {
      "epoch": 0.632279534109817,
      "grad_norm": 1.5107591152191162,
      "learning_rate": 7.357434578732416e-05,
      "loss": 0.5814,
      "step": 4180
    },
    {
      "epoch": 0.6353047950385721,
      "grad_norm": 1.4253389835357666,
      "learning_rate": 7.296929360157315e-05,
      "loss": 0.6542,
      "step": 4200
    },
    {
      "epoch": 0.6353047950385721,
      "eval_loss": 0.6301295161247253,
      "eval_runtime": 19.6796,
      "eval_samples_per_second": 21.545,
      "eval_steps_per_second": 21.545,
      "step": 4200
    },
    {
      "epoch": 0.6383300559673272,
      "grad_norm": 1.5007896423339844,
      "learning_rate": 7.236424141582212e-05,
      "loss": 0.5654,
      "step": 4220
    },
    {
      "epoch": 0.6413553168960823,
      "grad_norm": 1.9847922325134277,
      "learning_rate": 7.17591892300711e-05,
      "loss": 0.5729,
      "step": 4240
    },
    {
      "epoch": 0.6443805778248374,
      "grad_norm": 1.5803087949752808,
      "learning_rate": 7.115413704432008e-05,
      "loss": 0.5855,
      "step": 4260
    },
    {
      "epoch": 0.6474058387535925,
      "grad_norm": 1.288625955581665,
      "learning_rate": 7.054908485856906e-05,
      "loss": 0.612,
      "step": 4280
    },
    {
      "epoch": 0.6504310996823476,
      "grad_norm": 1.9828282594680786,
      "learning_rate": 6.994403267281804e-05,
      "loss": 0.5662,
      "step": 4300
    },
    {
      "epoch": 0.6504310996823476,
      "eval_loss": 0.6354532837867737,
      "eval_runtime": 19.6624,
      "eval_samples_per_second": 21.564,
      "eval_steps_per_second": 21.564,
      "step": 4300
    },
    {
      "epoch": 0.6534563606111027,
      "grad_norm": 1.1535242795944214,
      "learning_rate": 6.933898048706702e-05,
      "loss": 0.5534,
      "step": 4320
    },
    {
      "epoch": 0.6564816215398578,
      "grad_norm": 1.658596396446228,
      "learning_rate": 6.873392830131599e-05,
      "loss": 0.5864,
      "step": 4340
    },
    {
      "epoch": 0.6595068824686129,
      "grad_norm": 2.6359734535217285,
      "learning_rate": 6.812887611556497e-05,
      "loss": 0.5446,
      "step": 4360
    },
    {
      "epoch": 0.662532143397368,
      "grad_norm": 1.6015686988830566,
      "learning_rate": 6.752382392981394e-05,
      "loss": 0.5947,
      "step": 4380
    },
    {
      "epoch": 0.6655574043261231,
      "grad_norm": 1.2767328023910522,
      "learning_rate": 6.691877174406293e-05,
      "loss": 0.5497,
      "step": 4400
    },
    {
      "epoch": 0.6655574043261231,
      "eval_loss": 0.6351439356803894,
      "eval_runtime": 19.6824,
      "eval_samples_per_second": 21.542,
      "eval_steps_per_second": 21.542,
      "step": 4400
    },
    {
      "epoch": 0.6685826652548782,
      "grad_norm": 2.5668935775756836,
      "learning_rate": 6.63137195583119e-05,
      "loss": 0.6357,
      "step": 4420
    },
    {
      "epoch": 0.6716079261836333,
      "grad_norm": 1.3585562705993652,
      "learning_rate": 6.570866737256089e-05,
      "loss": 0.6397,
      "step": 4440
    },
    {
      "epoch": 0.6746331871123884,
      "grad_norm": 0.7071166634559631,
      "learning_rate": 6.510361518680986e-05,
      "loss": 0.6155,
      "step": 4460
    },
    {
      "epoch": 0.6776584480411435,
      "grad_norm": 2.0334441661834717,
      "learning_rate": 6.449856300105884e-05,
      "loss": 0.5885,
      "step": 4480
    },
    {
      "epoch": 0.6806837089698986,
      "grad_norm": 2.111732244491577,
      "learning_rate": 6.389351081530782e-05,
      "loss": 0.5898,
      "step": 4500
    },
    {
      "epoch": 0.6806837089698986,
      "eval_loss": 0.6266644597053528,
      "eval_runtime": 19.6987,
      "eval_samples_per_second": 21.524,
      "eval_steps_per_second": 21.524,
      "step": 4500
    },
    {
      "epoch": 0.6837089698986537,
      "grad_norm": 2.1817758083343506,
      "learning_rate": 6.32884586295568e-05,
      "loss": 0.643,
      "step": 4520
    },
    {
      "epoch": 0.6867342308274088,
      "grad_norm": 2.1031346321105957,
      "learning_rate": 6.268340644380579e-05,
      "loss": 0.5996,
      "step": 4540
    },
    {
      "epoch": 0.689759491756164,
      "grad_norm": 1.308290958404541,
      "learning_rate": 6.207835425805476e-05,
      "loss": 0.5648,
      "step": 4560
    },
    {
      "epoch": 0.6927847526849191,
      "grad_norm": 1.3018648624420166,
      "learning_rate": 6.147330207230373e-05,
      "loss": 0.5694,
      "step": 4580
    },
    {
      "epoch": 0.6958100136136742,
      "grad_norm": 1.220927357673645,
      "learning_rate": 6.086824988655272e-05,
      "loss": 0.5425,
      "step": 4600
    },
    {
      "epoch": 0.6958100136136742,
      "eval_loss": 0.6244776248931885,
      "eval_runtime": 19.7089,
      "eval_samples_per_second": 21.513,
      "eval_steps_per_second": 21.513,
      "step": 4600
    },
    {
      "epoch": 0.6988352745424293,
      "grad_norm": 1.1122652292251587,
      "learning_rate": 6.02631977008017e-05,
      "loss": 0.5784,
      "step": 4620
    },
    {
      "epoch": 0.7018605354711844,
      "grad_norm": 1.5445034503936768,
      "learning_rate": 5.9658145515050676e-05,
      "loss": 0.6712,
      "step": 4640
    },
    {
      "epoch": 0.7048857963999395,
      "grad_norm": 1.06612229347229,
      "learning_rate": 5.905309332929966e-05,
      "loss": 0.6313,
      "step": 4660
    },
    {
      "epoch": 0.7079110573286946,
      "grad_norm": 2.085239887237549,
      "learning_rate": 5.844804114354864e-05,
      "loss": 0.5708,
      "step": 4680
    },
    {
      "epoch": 0.7109363182574497,
      "grad_norm": 1.854215145111084,
      "learning_rate": 5.784298895779762e-05,
      "loss": 0.5691,
      "step": 4700
    },
    {
      "epoch": 0.7109363182574497,
      "eval_loss": 0.6217154860496521,
      "eval_runtime": 19.6733,
      "eval_samples_per_second": 21.552,
      "eval_steps_per_second": 21.552,
      "step": 4700
    },
    {
      "epoch": 0.7139615791862048,
      "grad_norm": 1.3937352895736694,
      "learning_rate": 5.72379367720466e-05,
      "loss": 0.6637,
      "step": 4720
    },
    {
      "epoch": 0.71698684011496,
      "grad_norm": 1.9593392610549927,
      "learning_rate": 5.663288458629557e-05,
      "loss": 0.6539,
      "step": 4740
    },
    {
      "epoch": 0.720012101043715,
      "grad_norm": 2.7637104988098145,
      "learning_rate": 5.602783240054455e-05,
      "loss": 0.5396,
      "step": 4760
    },
    {
      "epoch": 0.7230373619724701,
      "grad_norm": 1.7538548707962036,
      "learning_rate": 5.542278021479352e-05,
      "loss": 0.5945,
      "step": 4780
    },
    {
      "epoch": 0.7260626229012253,
      "grad_norm": 1.5895899534225464,
      "learning_rate": 5.48177280290425e-05,
      "loss": 0.5493,
      "step": 4800
    },
    {
      "epoch": 0.7260626229012253,
      "eval_loss": 0.6217162609100342,
      "eval_runtime": 19.6809,
      "eval_samples_per_second": 21.544,
      "eval_steps_per_second": 21.544,
      "step": 4800
    },
    {
      "epoch": 0.7290878838299804,
      "grad_norm": 1.282570242881775,
      "learning_rate": 5.421267584329148e-05,
      "loss": 0.5297,
      "step": 4820
    },
    {
      "epoch": 0.7321131447587355,
      "grad_norm": 0.9859206080436707,
      "learning_rate": 5.360762365754046e-05,
      "loss": 0.6041,
      "step": 4840
    },
    {
      "epoch": 0.7351384056874906,
      "grad_norm": 1.8725614547729492,
      "learning_rate": 5.3002571471789444e-05,
      "loss": 0.5309,
      "step": 4860
    },
    {
      "epoch": 0.7381636666162457,
      "grad_norm": 2.3700790405273438,
      "learning_rate": 5.239751928603842e-05,
      "loss": 0.6275,
      "step": 4880
    },
    {
      "epoch": 0.7411889275450008,
      "grad_norm": 2.040815591812134,
      "learning_rate": 5.17924671002874e-05,
      "loss": 0.5348,
      "step": 4900
    },
    {
      "epoch": 0.7411889275450008,
      "eval_loss": 0.622439980506897,
      "eval_runtime": 19.6748,
      "eval_samples_per_second": 21.55,
      "eval_steps_per_second": 21.55,
      "step": 4900
    },
    {
      "epoch": 0.7442141884737559,
      "grad_norm": 1.816895842552185,
      "learning_rate": 5.118741491453638e-05,
      "loss": 0.5859,
      "step": 4920
    },
    {
      "epoch": 0.747239449402511,
      "grad_norm": 1.7077113389968872,
      "learning_rate": 5.058236272878536e-05,
      "loss": 0.678,
      "step": 4940
    },
    {
      "epoch": 0.7502647103312661,
      "grad_norm": 2.1531569957733154,
      "learning_rate": 4.997731054303434e-05,
      "loss": 0.5776,
      "step": 4960
    },
    {
      "epoch": 0.7532899712600212,
      "grad_norm": 1.7928653955459595,
      "learning_rate": 4.937225835728332e-05,
      "loss": 0.5827,
      "step": 4980
    },
    {
      "epoch": 0.7563152321887763,
      "grad_norm": 1.5337550640106201,
      "learning_rate": 4.8767206171532296e-05,
      "loss": 0.6227,
      "step": 5000
    },
    {
      "epoch": 0.7563152321887763,
      "eval_loss": 0.6182581782341003,
      "eval_runtime": 19.6602,
      "eval_samples_per_second": 21.566,
      "eval_steps_per_second": 21.566,
      "step": 5000
    },
    {
      "epoch": 0.7593404931175314,
      "grad_norm": 1.6668325662612915,
      "learning_rate": 4.816215398578128e-05,
      "loss": 0.5559,
      "step": 5020
    },
    {
      "epoch": 0.7623657540462865,
      "grad_norm": 1.4262657165527344,
      "learning_rate": 4.755710180003026e-05,
      "loss": 0.6054,
      "step": 5040
    },
    {
      "epoch": 0.7653910149750416,
      "grad_norm": 1.1484981775283813,
      "learning_rate": 4.695204961427924e-05,
      "loss": 0.6393,
      "step": 5060
    },
    {
      "epoch": 0.7684162759037967,
      "grad_norm": 1.6024112701416016,
      "learning_rate": 4.634699742852821e-05,
      "loss": 0.6656,
      "step": 5080
    },
    {
      "epoch": 0.7714415368325518,
      "grad_norm": 1.442970633506775,
      "learning_rate": 4.574194524277719e-05,
      "loss": 0.5197,
      "step": 5100
    },
    {
      "epoch": 0.7714415368325518,
      "eval_loss": 0.6164485812187195,
      "eval_runtime": 19.6645,
      "eval_samples_per_second": 21.562,
      "eval_steps_per_second": 21.562,
      "step": 5100
    },
    {
      "epoch": 0.7744667977613069,
      "grad_norm": 1.2717156410217285,
      "learning_rate": 4.513689305702617e-05,
      "loss": 0.4804,
      "step": 5120
    },
    {
      "epoch": 0.777492058690062,
      "grad_norm": 3.101834297180176,
      "learning_rate": 4.453184087127515e-05,
      "loss": 0.6741,
      "step": 5140
    },
    {
      "epoch": 0.7805173196188171,
      "grad_norm": 1.248887300491333,
      "learning_rate": 4.392678868552413e-05,
      "loss": 0.5172,
      "step": 5160
    },
    {
      "epoch": 0.7835425805475722,
      "grad_norm": 2.1275620460510254,
      "learning_rate": 4.332173649977311e-05,
      "loss": 0.6023,
      "step": 5180
    },
    {
      "epoch": 0.7865678414763273,
      "grad_norm": 3.2258241176605225,
      "learning_rate": 4.271668431402209e-05,
      "loss": 0.5794,
      "step": 5200
    },
    {
      "epoch": 0.7865678414763273,
      "eval_loss": 0.6185361742973328,
      "eval_runtime": 19.6706,
      "eval_samples_per_second": 21.555,
      "eval_steps_per_second": 21.555,
      "step": 5200
    },
    {
      "epoch": 0.7895931024050824,
      "grad_norm": 2.027507781982422,
      "learning_rate": 4.2111632128271064e-05,
      "loss": 0.6111,
      "step": 5220
    },
    {
      "epoch": 0.7926183633338375,
      "grad_norm": 1.865124225616455,
      "learning_rate": 4.1506579942520045e-05,
      "loss": 0.6647,
      "step": 5240
    },
    {
      "epoch": 0.7956436242625926,
      "grad_norm": 1.6763452291488647,
      "learning_rate": 4.0901527756769025e-05,
      "loss": 0.5482,
      "step": 5260
    },
    {
      "epoch": 0.7986688851913477,
      "grad_norm": 2.378744602203369,
      "learning_rate": 4.0296475571018e-05,
      "loss": 0.612,
      "step": 5280
    },
    {
      "epoch": 0.8016941461201028,
      "grad_norm": 2.4952926635742188,
      "learning_rate": 3.969142338526698e-05,
      "loss": 0.6385,
      "step": 5300
    },
    {
      "epoch": 0.8016941461201028,
      "eval_loss": 0.6166008114814758,
      "eval_runtime": 19.6589,
      "eval_samples_per_second": 21.568,
      "eval_steps_per_second": 21.568,
      "step": 5300
    },
    {
      "epoch": 0.8047194070488579,
      "grad_norm": 1.7037837505340576,
      "learning_rate": 3.908637119951596e-05,
      "loss": 0.5773,
      "step": 5320
    },
    {
      "epoch": 0.807744667977613,
      "grad_norm": 2.328321933746338,
      "learning_rate": 3.8481319013764935e-05,
      "loss": 0.6354,
      "step": 5340
    },
    {
      "epoch": 0.8107699289063681,
      "grad_norm": 1.6723679304122925,
      "learning_rate": 3.7876266828013916e-05,
      "loss": 0.5645,
      "step": 5360
    },
    {
      "epoch": 0.8137951898351233,
      "grad_norm": 1.8474266529083252,
      "learning_rate": 3.7271214642262896e-05,
      "loss": 0.6049,
      "step": 5380
    },
    {
      "epoch": 0.8168204507638784,
      "grad_norm": 2.4089505672454834,
      "learning_rate": 3.666616245651188e-05,
      "loss": 0.5689,
      "step": 5400
    },
    {
      "epoch": 0.8168204507638784,
      "eval_loss": 0.6157885193824768,
      "eval_runtime": 19.6683,
      "eval_samples_per_second": 21.558,
      "eval_steps_per_second": 21.558,
      "step": 5400
    },
    {
      "epoch": 0.8198457116926335,
      "grad_norm": 3.556739330291748,
      "learning_rate": 3.606111027076086e-05,
      "loss": 0.649,
      "step": 5420
    },
    {
      "epoch": 0.8228709726213886,
      "grad_norm": 1.960934042930603,
      "learning_rate": 3.545605808500984e-05,
      "loss": 0.5565,
      "step": 5440
    },
    {
      "epoch": 0.8258962335501437,
      "grad_norm": 1.703340768814087,
      "learning_rate": 3.485100589925881e-05,
      "loss": 0.5353,
      "step": 5460
    },
    {
      "epoch": 0.8289214944788988,
      "grad_norm": 1.0524885654449463,
      "learning_rate": 3.424595371350779e-05,
      "loss": 0.5241,
      "step": 5480
    },
    {
      "epoch": 0.831946755407654,
      "grad_norm": 1.897094488143921,
      "learning_rate": 3.364090152775677e-05,
      "loss": 0.5974,
      "step": 5500
    },
    {
      "epoch": 0.831946755407654,
      "eval_loss": 0.6153029799461365,
      "eval_runtime": 19.666,
      "eval_samples_per_second": 21.56,
      "eval_steps_per_second": 21.56,
      "step": 5500
    },
    {
      "epoch": 0.834972016336409,
      "grad_norm": 1.6679359674453735,
      "learning_rate": 3.303584934200575e-05,
      "loss": 0.5323,
      "step": 5520
    },
    {
      "epoch": 0.8379972772651642,
      "grad_norm": 2.1145694255828857,
      "learning_rate": 3.243079715625473e-05,
      "loss": 0.5662,
      "step": 5540
    },
    {
      "epoch": 0.8410225381939193,
      "grad_norm": 2.267115354537964,
      "learning_rate": 3.182574497050371e-05,
      "loss": 0.584,
      "step": 5560
    },
    {
      "epoch": 0.8440477991226744,
      "grad_norm": 2.339047431945801,
      "learning_rate": 3.1220692784752684e-05,
      "loss": 0.5247,
      "step": 5580
    },
    {
      "epoch": 0.8470730600514295,
      "grad_norm": 2.870547294616699,
      "learning_rate": 3.0615640599001664e-05,
      "loss": 0.6743,
      "step": 5600
    },
    {
      "epoch": 0.8470730600514295,
      "eval_loss": 0.613110363483429,
      "eval_runtime": 19.6678,
      "eval_samples_per_second": 21.558,
      "eval_steps_per_second": 21.558,
      "step": 5600
    },
    {
      "epoch": 0.8500983209801846,
      "grad_norm": 1.661160945892334,
      "learning_rate": 3.0010588413250645e-05,
      "loss": 0.5386,
      "step": 5620
    },
    {
      "epoch": 0.8531235819089397,
      "grad_norm": 6.794570446014404,
      "learning_rate": 2.9405536227499626e-05,
      "loss": 0.619,
      "step": 5640
    },
    {
      "epoch": 0.8561488428376948,
      "grad_norm": 2.0072989463806152,
      "learning_rate": 2.8800484041748603e-05,
      "loss": 0.5328,
      "step": 5660
    },
    {
      "epoch": 0.8591741037664499,
      "grad_norm": 1.3582141399383545,
      "learning_rate": 2.8195431855997584e-05,
      "loss": 0.52,
      "step": 5680
    },
    {
      "epoch": 0.862199364695205,
      "grad_norm": 2.289747953414917,
      "learning_rate": 2.7590379670246558e-05,
      "loss": 0.5417,
      "step": 5700
    },
    {
      "epoch": 0.862199364695205,
      "eval_loss": 0.6105179786682129,
      "eval_runtime": 19.6621,
      "eval_samples_per_second": 21.564,
      "eval_steps_per_second": 21.564,
      "step": 5700
    },
    {
      "epoch": 0.8652246256239601,
      "grad_norm": 1.263554334640503,
      "learning_rate": 2.698532748449554e-05,
      "loss": 0.5687,
      "step": 5720
    },
    {
      "epoch": 0.8682498865527152,
      "grad_norm": 2.36222243309021,
      "learning_rate": 2.6380275298744516e-05,
      "loss": 0.5824,
      "step": 5740
    },
    {
      "epoch": 0.8712751474814703,
      "grad_norm": 2.3081843852996826,
      "learning_rate": 2.5775223112993497e-05,
      "loss": 0.6167,
      "step": 5760
    },
    {
      "epoch": 0.8743004084102254,
      "grad_norm": 1.4545581340789795,
      "learning_rate": 2.5170170927242474e-05,
      "loss": 0.5286,
      "step": 5780
    },
    {
      "epoch": 0.8773256693389805,
      "grad_norm": 1.5601063966751099,
      "learning_rate": 2.4565118741491455e-05,
      "loss": 0.5808,
      "step": 5800
    },
    {
      "epoch": 0.8773256693389805,
      "eval_loss": 0.6112935543060303,
      "eval_runtime": 19.661,
      "eval_samples_per_second": 21.566,
      "eval_steps_per_second": 21.566,
      "step": 5800
    },
    {
      "epoch": 0.8803509302677356,
      "grad_norm": 2.8466145992279053,
      "learning_rate": 2.3960066555740436e-05,
      "loss": 0.5848,
      "step": 5820
    },
    {
      "epoch": 0.8833761911964907,
      "grad_norm": 2.5415332317352295,
      "learning_rate": 2.335501436998941e-05,
      "loss": 0.5751,
      "step": 5840
    },
    {
      "epoch": 0.8864014521252458,
      "grad_norm": 1.702337384223938,
      "learning_rate": 2.274996218423839e-05,
      "loss": 0.5814,
      "step": 5860
    },
    {
      "epoch": 0.8894267130540009,
      "grad_norm": 1.6751649379730225,
      "learning_rate": 2.214490999848737e-05,
      "loss": 0.5125,
      "step": 5880
    },
    {
      "epoch": 0.892451973982756,
      "grad_norm": 1.8755755424499512,
      "learning_rate": 2.153985781273635e-05,
      "loss": 0.5857,
      "step": 5900
    },
    {
      "epoch": 0.892451973982756,
      "eval_loss": 0.6097957491874695,
      "eval_runtime": 19.6724,
      "eval_samples_per_second": 21.553,
      "eval_steps_per_second": 21.553,
      "step": 5900
    },
    {
      "epoch": 0.8954772349115111,
      "grad_norm": 1.7056057453155518,
      "learning_rate": 2.093480562698533e-05,
      "loss": 0.5032,
      "step": 5920
    },
    {
      "epoch": 0.8985024958402662,
      "grad_norm": 1.5385397672653198,
      "learning_rate": 2.032975344123431e-05,
      "loss": 0.5582,
      "step": 5940
    },
    {
      "epoch": 0.9015277567690213,
      "grad_norm": 1.578389048576355,
      "learning_rate": 1.9724701255483284e-05,
      "loss": 0.5793,
      "step": 5960
    },
    {
      "epoch": 0.9045530176977764,
      "grad_norm": 1.0970454216003418,
      "learning_rate": 1.9119649069732265e-05,
      "loss": 0.5187,
      "step": 5980
    },
    {
      "epoch": 0.9075782786265315,
      "grad_norm": 1.8526058197021484,
      "learning_rate": 1.8514596883981246e-05,
      "loss": 0.6186,
      "step": 6000
    },
    {
      "epoch": 0.9075782786265315,
      "eval_loss": 0.6074638962745667,
      "eval_runtime": 19.66,
      "eval_samples_per_second": 21.567,
      "eval_steps_per_second": 21.567,
      "step": 6000
    },
    {
      "epoch": 0.9106035395552866,
      "grad_norm": 2.2413108348846436,
      "learning_rate": 1.7909544698230223e-05,
      "loss": 0.5126,
      "step": 6020
    },
    {
      "epoch": 0.9136288004840417,
      "grad_norm": 1.8771718740463257,
      "learning_rate": 1.7304492512479204e-05,
      "loss": 0.5258,
      "step": 6040
    },
    {
      "epoch": 0.9166540614127968,
      "grad_norm": 2.5152790546417236,
      "learning_rate": 1.669944032672818e-05,
      "loss": 0.4895,
      "step": 6060
    },
    {
      "epoch": 0.9196793223415519,
      "grad_norm": 1.4889684915542603,
      "learning_rate": 1.609438814097716e-05,
      "loss": 0.5153,
      "step": 6080
    },
    {
      "epoch": 0.922704583270307,
      "grad_norm": 1.673135757446289,
      "learning_rate": 1.548933595522614e-05,
      "loss": 0.5815,
      "step": 6100
    },
    {
      "epoch": 0.922704583270307,
      "eval_loss": 0.6073784232139587,
      "eval_runtime": 19.6657,
      "eval_samples_per_second": 21.56,
      "eval_steps_per_second": 21.56,
      "step": 6100
    },
    {
      "epoch": 0.9257298441990621,
      "grad_norm": 1.8237649202346802,
      "learning_rate": 1.4884283769475118e-05,
      "loss": 0.5764,
      "step": 6120
    },
    {
      "epoch": 0.9287551051278172,
      "grad_norm": 1.835431456565857,
      "learning_rate": 1.4279231583724097e-05,
      "loss": 0.6714,
      "step": 6140
    },
    {
      "epoch": 0.9317803660565723,
      "grad_norm": 1.2149242162704468,
      "learning_rate": 1.3674179397973075e-05,
      "loss": 0.5885,
      "step": 6160
    },
    {
      "epoch": 0.9348056269853274,
      "grad_norm": 2.1157445907592773,
      "learning_rate": 1.3069127212222054e-05,
      "loss": 0.5509,
      "step": 6180
    },
    {
      "epoch": 0.9378308879140826,
      "grad_norm": 2.056856870651245,
      "learning_rate": 1.2464075026471033e-05,
      "loss": 0.5731,
      "step": 6200
    },
    {
      "epoch": 0.9378308879140826,
      "eval_loss": 0.6065577268600464,
      "eval_runtime": 19.6453,
      "eval_samples_per_second": 21.583,
      "eval_steps_per_second": 21.583,
      "step": 6200
    },
    {
      "epoch": 0.9408561488428377,
      "grad_norm": 1.6257832050323486,
      "learning_rate": 1.1859022840720014e-05,
      "loss": 0.5915,
      "step": 6220
    },
    {
      "epoch": 0.9438814097715928,
      "grad_norm": 2.0836875438690186,
      "learning_rate": 1.1253970654968991e-05,
      "loss": 0.4985,
      "step": 6240
    },
    {
      "epoch": 0.946906670700348,
      "grad_norm": 1.1032752990722656,
      "learning_rate": 1.064891846921797e-05,
      "loss": 0.617,
      "step": 6260
    },
    {
      "epoch": 0.949931931629103,
      "grad_norm": 2.030139207839966,
      "learning_rate": 1.004386628346695e-05,
      "loss": 0.6424,
      "step": 6280
    },
    {
      "epoch": 0.9529571925578582,
      "grad_norm": 1.5178083181381226,
      "learning_rate": 9.438814097715928e-06,
      "loss": 0.5089,
      "step": 6300
    },
    {
      "epoch": 0.9529571925578582,
      "eval_loss": 0.60560142993927,
      "eval_runtime": 19.6513,
      "eval_samples_per_second": 21.576,
      "eval_steps_per_second": 21.576,
      "step": 6300
    },
    {
      "epoch": 0.9559824534866133,
      "grad_norm": 2.4582595825195312,
      "learning_rate": 8.833761911964907e-06,
      "loss": 0.5342,
      "step": 6320
    },
    {
      "epoch": 0.9590077144153684,
      "grad_norm": 2.3047845363616943,
      "learning_rate": 8.228709726213886e-06,
      "loss": 0.6,
      "step": 6340
    },
    {
      "epoch": 0.9620329753441235,
      "grad_norm": 1.7592418193817139,
      "learning_rate": 7.6236575404628655e-06,
      "loss": 0.5716,
      "step": 6360
    },
    {
      "epoch": 0.9650582362728786,
      "grad_norm": 1.8563963174819946,
      "learning_rate": 7.018605354711844e-06,
      "loss": 0.6622,
      "step": 6380
    },
    {
      "epoch": 0.9680834972016337,
      "grad_norm": 1.7197295427322388,
      "learning_rate": 6.413553168960823e-06,
      "loss": 0.6626,
      "step": 6400
    },
    {
      "epoch": 0.9680834972016337,
      "eval_loss": 0.6048600673675537,
      "eval_runtime": 19.6609,
      "eval_samples_per_second": 21.566,
      "eval_steps_per_second": 21.566,
      "step": 6400
    },
    {
      "epoch": 0.9711087581303888,
      "grad_norm": 1.1352485418319702,
      "learning_rate": 5.808500983209802e-06,
      "loss": 0.5118,
      "step": 6420
    },
    {
      "epoch": 0.9741340190591439,
      "grad_norm": 2.772352695465088,
      "learning_rate": 5.203448797458781e-06,
      "loss": 0.6248,
      "step": 6440
    },
    {
      "epoch": 0.977159279987899,
      "grad_norm": 1.613295316696167,
      "learning_rate": 4.59839661170776e-06,
      "loss": 0.5721,
      "step": 6460
    },
    {
      "epoch": 0.9801845409166541,
      "grad_norm": 1.4326534271240234,
      "learning_rate": 3.993344425956739e-06,
      "loss": 0.5803,
      "step": 6480
    },
    {
      "epoch": 0.9832098018454092,
      "grad_norm": 1.478039264678955,
      "learning_rate": 3.3882922402057177e-06,
      "loss": 0.5755,
      "step": 6500
    },
    {
      "epoch": 0.9832098018454092,
      "eval_loss": 0.6038236618041992,
      "eval_runtime": 19.668,
      "eval_samples_per_second": 21.558,
      "eval_steps_per_second": 21.558,
      "step": 6500
    },
    {
      "epoch": 0.9862350627741643,
      "grad_norm": 1.5722661018371582,
      "learning_rate": 2.7832400544546967e-06,
      "loss": 0.4762,
      "step": 6520
    },
    {
      "epoch": 0.9892603237029194,
      "grad_norm": 1.7794491052627563,
      "learning_rate": 2.178187868703676e-06,
      "loss": 0.5331,
      "step": 6540
    },
    {
      "epoch": 0.9922855846316745,
      "grad_norm": 1.4191921949386597,
      "learning_rate": 1.5731356829526546e-06,
      "loss": 0.5003,
      "step": 6560
    },
    {
      "epoch": 0.9953108455604296,
      "grad_norm": 1.7433981895446777,
      "learning_rate": 9.680834972016337e-07,
      "loss": 0.5871,
      "step": 6580
    },
    {
      "epoch": 0.9983361064891847,
      "grad_norm": 1.911280870437622,
      "learning_rate": 3.630313114506126e-07,
      "loss": 0.5563,
      "step": 6600
    },
    {
      "epoch": 0.9983361064891847,
      "eval_loss": 0.6038495302200317,
      "eval_runtime": 19.6881,
      "eval_samples_per_second": 21.536,
      "eval_steps_per_second": 21.536,
      "step": 6600
    }
  ],
  "logging_steps": 20,
  "max_steps": 6611,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2866311897993216.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
